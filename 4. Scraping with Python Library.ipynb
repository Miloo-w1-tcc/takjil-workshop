{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "second-phrase"
   },
   "source": [
    "# Getting Information from Social Media (Twitter)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "proof-stand"
   },
   "source": [
    "<img src=\"Images/pic1.JPG\" alt=\"Drawing\"/>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "sexual-vault"
   },
   "source": [
    "+ **Web Crawling** merupakan suatu program/sistem/script otomatis yang dengan suatu metode tertentu melakukan scanning halaman-halaman yang ada dalam sebuah website. Web crawling menlakukan indexing dan dapat mengambil informasi-informasi pada halaman website. Hasil dari web crawling biasanya akan digunakan untuk mempelajari isi dari halaman-halaman website.\n",
    "+ **Streaming** merupakan \n",
    "+ **Web Scraping** merupakan suatu kegiatan yang dilakukan untuk mengambil informasi dari halaman website. Web scraping biasanya mengambil informasi dari HTML yang terdapat pada halaman website."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "prospective-orchestra"
   },
   "source": [
    "### Contoh Scraper/crawler"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "velvet-titanium"
   },
   "source": [
    "**Official Scraper/Crawler**   : Tweepy, Scrapy\n",
    "\n",
    "**Unofficial Scraper/Crawler** : Twitterscraper, Scweet\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "driving-distinction"
   },
   "source": [
    "### Example Scraping\n",
    "\n",
    "Pada sesi ini, kita akan menggunakan salah satu contoh web scraper yaitu Scweet. Scweet melakukan scraping pada halaman website twitter. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "split-algeria"
   },
   "source": [
    "#### 1. Import needed library"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "connected-carbon"
   },
   "source": [
    "Library yang dibutuhkan untuk scraping kali ini adalah scweet dan pandas"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 9032,
     "status": "ok",
     "timestamp": 1620128986898,
     "user": {
      "displayName": "Naufal Dzaky Anwari",
      "photoUrl": "https://lh3.googleusercontent.com/a-/AOh14GjUfVofiHSrNTGJZHJIPJwL0sf7lvJPIrE2d4XMAw=s64",
      "userId": "06742799176171152084"
     },
     "user_tz": -420
    },
    "id": "lI1hgalzNgvm",
    "outputId": "98c3da84-fb57-4edb-a9d0-73616e2e2579"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: Scweet==1.0 in c:\\users\\dzaky\\anaconda3\\lib\\site-packages (1.0)\n",
      "Requirement already satisfied: urllib3 in c:\\users\\dzaky\\anaconda3\\lib\\site-packages (from Scweet==1.0) (1.25.11)\n",
      "Requirement already satisfied: pandas in c:\\users\\dzaky\\anaconda3\\lib\\site-packages (from Scweet==1.0) (1.1.3)\n",
      "Requirement already satisfied: selenium in c:\\users\\dzaky\\anaconda3\\lib\\site-packages (from Scweet==1.0) (3.141.0)\n",
      "Requirement already satisfied: python-dotenv in c:\\users\\dzaky\\anaconda3\\lib\\site-packages (from Scweet==1.0) (0.17.1)\n",
      "Requirement already satisfied: chromedriver-autoinstaller in c:\\users\\dzaky\\anaconda3\\lib\\site-packages (from Scweet==1.0) (0.2.2)\n",
      "Requirement already satisfied: python-dateutil>=2.7.3 in c:\\users\\dzaky\\anaconda3\\lib\\site-packages (from pandas->Scweet==1.0) (2.8.1)\n",
      "Requirement already satisfied: pytz>=2017.2 in c:\\users\\dzaky\\anaconda3\\lib\\site-packages (from pandas->Scweet==1.0) (2020.1)\n",
      "Requirement already satisfied: numpy>=1.15.4 in c:\\users\\dzaky\\anaconda3\\lib\\site-packages (from pandas->Scweet==1.0) (1.19.2)\n",
      "Requirement already satisfied: six>=1.5 in c:\\users\\dzaky\\anaconda3\\lib\\site-packages (from python-dateutil>=2.7.3->pandas->Scweet==1.0) (1.15.0)\n",
      "Requirement already satisfied: pandas==1.1.3 in c:\\users\\dzaky\\anaconda3\\lib\\site-packages (1.1.3)\n",
      "Requirement already satisfied: numpy>=1.15.4 in c:\\users\\dzaky\\anaconda3\\lib\\site-packages (from pandas==1.1.3) (1.19.2)\n",
      "Requirement already satisfied: python-dateutil>=2.7.3 in c:\\users\\dzaky\\anaconda3\\lib\\site-packages (from pandas==1.1.3) (2.8.1)\n",
      "Requirement already satisfied: pytz>=2017.2 in c:\\users\\dzaky\\anaconda3\\lib\\site-packages (from pandas==1.1.3) (2020.1)\n",
      "Requirement already satisfied: six>=1.5 in c:\\users\\dzaky\\anaconda3\\lib\\site-packages (from python-dateutil>=2.7.3->pandas==1.1.3) (1.15.0)\n"
     ]
    }
   ],
   "source": [
    "!pip install Scweet==1.0\n",
    "!pip install pandas==1.1.3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "executionInfo": {
     "elapsed": 1655,
     "status": "ok",
     "timestamp": 1620128992832,
     "user": {
      "displayName": "Naufal Dzaky Anwari",
      "photoUrl": "https://lh3.googleusercontent.com/a-/AOh14GjUfVofiHSrNTGJZHJIPJwL0sf7lvJPIrE2d4XMAw=s64",
      "userId": "06742799176171152084"
     },
     "user_tz": -420
    },
    "id": "unlike-minneapolis"
   },
   "outputs": [],
   "source": [
    "from Scweet.scweet import scrap\n",
    "from Scweet.user import get_user_information, get_users_following, get_users_followers\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'1.1.3'"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pd.__version__"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "random-element"
   },
   "source": [
    "#### 2. Scrape tweet with certain words"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "convinced-miami"
   },
   "source": [
    "dengan menggunakan Scweet, kita dapat mengambil top tweets yang mengandung kata tertentu. caranya dengan menggunakan module scrap yang tersedia pada library Scweet."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 433
    },
    "executionInfo": {
     "elapsed": 2056,
     "status": "error",
     "timestamp": 1620128998741,
     "user": {
      "displayName": "Naufal Dzaky Anwari",
      "photoUrl": "https://lh3.googleusercontent.com/a-/AOh14GjUfVofiHSrNTGJZHJIPJwL0sf7lvJPIrE2d4XMAw=s64",
      "userId": "06742799176171152084"
     },
     "user_tz": -420
    },
    "id": "strong-relief",
    "outputId": "23b35e02-150f-45c0-b71b-737a5c3def31"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Scraping on headless mode.\n",
      "looking for tweets between 2021-04-28 and 2021-04-29 ...\n",
      " path : https://twitter.com/search?q=(kurma)%20until%3A2021-04-29%20since%3A2021-04-28%20%20-filter%3Areplies&src=typed_query&lf=on\n",
      "scroll  1\n",
      "scroll  2\n",
      "looking for tweets between 2021-04-29 and 2021-04-30 ...\n",
      " path : https://twitter.com/search?q=(kurma)%20until%3A2021-04-30%20since%3A2021-04-29%20%20-filter%3Areplies&src=typed_query&lf=on\n",
      "Tweet made at: 2021-04-29T11:21:06.000Z is found.\n",
      "Tweet made at: 2021-04-29T12:06:34.000Z is found.\n",
      "scroll  1\n",
      "scroll  2\n",
      "scroll  3\n"
     ]
    }
   ],
   "source": [
    "# keywords\n",
    "keywords = ['kurma']\n",
    "\n",
    "# Date interval\n",
    "initial_date = '2021-04-28'\n",
    "finish_date = '2021-04-30'\n",
    "\n",
    "all_datas = []\n",
    "for x in keywords:\n",
    "    data = scrap(words=x,\n",
    "                 start_date=initial_date,\n",
    "                 max_date=finish_date,\n",
    "                 from_account=None,\n",
    "                 interval=1, \n",
    "                 headless=True,\n",
    "                 save_images=False,\n",
    "                 display_type=None,\n",
    "                 resume=False,\n",
    "                 filter_replies=True,\n",
    "                 proximity=True)\n",
    "    \n",
    "    data['keyword'] = x\n",
    "    all_datas.append(data)\n",
    "\n",
    "all_datas = pd.concat(all_datas)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "id": "polished-jenny",
    "outputId": "c22488d5-c278-4d57-a165-e3f2f90a688e"
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>UserScreenName</th>\n",
       "      <th>UserName</th>\n",
       "      <th>Timestamp</th>\n",
       "      <th>Text</th>\n",
       "      <th>Embedded_text</th>\n",
       "      <th>Emojis</th>\n",
       "      <th>Comments</th>\n",
       "      <th>Likes</th>\n",
       "      <th>Retweets</th>\n",
       "      <th>Image link</th>\n",
       "      <th>Tweet URL</th>\n",
       "      <th>keyword</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Lovaditya Dhika</td>\n",
       "      <td>@lovaditya</td>\n",
       "      <td>2021-04-29T11:21:06.000Z</td>\n",
       "      <td>bales chat panda edisi mikir bgt myampe baru s...</td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td>[]</td>\n",
       "      <td>https://twitter.com/lovaditya/status/138772864...</td>\n",
       "      <td>kurma</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>ùêøùëúùìãùëí¬∞ùìÇùìéùìàùëíùìÅùíª</td>\n",
       "      <td>@Henny_purlina</td>\n",
       "      <td>2021-04-29T12:06:34.000Z</td>\n",
       "      <td>Maem kurma purun ?</td>\n",
       "      <td></td>\n",
       "      <td>üòå üíú</td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td>[]</td>\n",
       "      <td>https://twitter.com/Henny_purlina/status/13877...</td>\n",
       "      <td>kurma</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    UserScreenName        UserName                 Timestamp  \\\n",
       "0  Lovaditya Dhika      @lovaditya  2021-04-29T11:21:06.000Z   \n",
       "1      ùêøùëúùìãùëí¬∞ùìÇùìéùìàùëíùìÅùíª  @Henny_purlina  2021-04-29T12:06:34.000Z   \n",
       "\n",
       "                                                Text Embedded_text Emojis  \\\n",
       "0  bales chat panda edisi mikir bgt myampe baru s...                        \n",
       "1                                 Maem kurma purun ?                  üòå üíú   \n",
       "\n",
       "  Comments Likes Retweets Image link  \\\n",
       "0                                 []   \n",
       "1                                 []   \n",
       "\n",
       "                                           Tweet URL keyword  \n",
       "0  https://twitter.com/lovaditya/status/138772864...   kurma  \n",
       "1  https://twitter.com/Henny_purlina/status/13877...   kurma  "
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "all_datas"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "id": "unknown-impossible",
    "outputId": "1c68b14c-6f82-44e5-b5ec-b5810c1b932a"
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>UserScreenName</th>\n",
       "      <th>UserName</th>\n",
       "      <th>Timestamp</th>\n",
       "      <th>Text</th>\n",
       "      <th>Embedded_text</th>\n",
       "      <th>Emojis</th>\n",
       "      <th>Comments</th>\n",
       "      <th>Likes</th>\n",
       "      <th>Retweets</th>\n",
       "      <th>Image link</th>\n",
       "      <th>Tweet URL</th>\n",
       "      <th>keyword</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "Empty DataFrame\n",
       "Columns: [UserScreenName, UserName, Timestamp, Text, Embedded_text, Emojis, Comments, Likes, Retweets, Image link, Tweet URL, keyword]\n",
       "Index: []"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "all_datas[all_datas['keyword'] == 'es buah']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "id": "lightweight-surfing"
   },
   "outputs": [],
   "source": [
    "# Save data to csv\n",
    "filename = 'all_keywordsv2.csv'\n",
    "all_datas.to_csv(filename, index=None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "id": "incorporated-chemical",
    "outputId": "670abc25-c7e3-448d-86bb-7edaeaf28648"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Scraping on headless mode.\n"
     ]
    }
   ],
   "source": [
    "hashtag = 'sopbuah'\n",
    "\n",
    "initial_date = '2021-04-28'\n",
    "finish_date = '2021-04-30'\n",
    "\n",
    "data = scrap(hashtag=hashtag,\n",
    "             start_date=initial_date,\n",
    "             max_date=finish_date,\n",
    "             from_account=None,\n",
    "             interval=5,\n",
    "             headless=True,\n",
    "             display_type=\"Top\",\n",
    "             save_images=False, \n",
    "             resume=False,\n",
    "             filter_replies=False,\n",
    "             proximity=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "id": "norman-hospital",
    "outputId": "ef61011f-67d1-41c9-9702-1f5d5434490e"
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>UserScreenName</th>\n",
       "      <th>UserName</th>\n",
       "      <th>Timestamp</th>\n",
       "      <th>Text</th>\n",
       "      <th>Embedded_text</th>\n",
       "      <th>Emojis</th>\n",
       "      <th>Comments</th>\n",
       "      <th>Likes</th>\n",
       "      <th>Retweets</th>\n",
       "      <th>Image link</th>\n",
       "      <th>Tweet URL</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "Empty DataFrame\n",
       "Columns: [UserScreenName, UserName, Timestamp, Text, Embedded_text, Emojis, Comments, Likes, Retweets, Image link, Tweet URL]\n",
       "Index: []"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "swiss-spanking"
   },
   "source": [
    "### Get the main information of a given list of users"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "id": "amazing-bottom",
    "outputId": "89313c32-04f6-4f2a-be7e-b494ad4a80b7"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Scraping on headless mode.\n",
      "--------------- @raisa6690 information : ---------------\n",
      "Following :  439\n",
      "Followers :  9M\n",
      "Location :  \n",
      "Join date :  Joined August 2009\n",
      "Birth date :  \n",
      "Description :  I'm a singer, in love forever with it. In it for the love of music, not for the glitter and gold :) Contact : Boim +628568526196 / adryboim@junirecords.com\n",
      "Website :  https://t.co/5H6zfx8M19?amp=1\n",
      "--------------- @isyanasarasvati information : ---------------\n",
      "Following :  98\n",
      "Followers :  268.5K\n",
      "Location :  \n",
      "Join date :  Joined October 2011\n",
      "Birth date :  \n",
      "Description :  Musician | \n",
      "@redrose_records\n",
      " | CP : +6281314155565 (Sarah)\n",
      "Website :  https://t.co/yU2UNpVQjX?amp=1\n"
     ]
    }
   ],
   "source": [
    "users = ['@raisa6690', '@isyanasarasvati']\n",
    "\n",
    "# this function return a list that contains : \n",
    "# [\"nb of following\",\"nb of followers\", \"join date\", \"birthdate\", \"location\", \"website\", \"description\"]\n",
    "\n",
    "users_info = get_user_information(users, headless=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "id": "novel-service",
    "outputId": "1cf729d8-1329-41a7-fbb5-9f2457f18e37"
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>nb of following</th>\n",
       "      <th>nb of followers</th>\n",
       "      <th>join date</th>\n",
       "      <th>birthdate</th>\n",
       "      <th>location</th>\n",
       "      <th>website</th>\n",
       "      <th>description</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>@raisa6690</th>\n",
       "      <td>439</td>\n",
       "      <td>9M</td>\n",
       "      <td>Joined August 2009</td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td>https://t.co/5H6zfx8M19?amp=1</td>\n",
       "      <td>I'm a singer, in love forever with it. In it f...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>@isyanasarasvati</th>\n",
       "      <td>98</td>\n",
       "      <td>268.5K</td>\n",
       "      <td>Joined October 2011</td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td>https://t.co/yU2UNpVQjX?amp=1</td>\n",
       "      <td>Musician | \\n@redrose_records\\n | CP : +628131...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                 nb of following nb of followers            join date  \\\n",
       "@raisa6690                   439              9M   Joined August 2009   \n",
       "@isyanasarasvati              98          268.5K  Joined October 2011   \n",
       "\n",
       "                 birthdate location                        website  \\\n",
       "@raisa6690                           https://t.co/5H6zfx8M19?amp=1   \n",
       "@isyanasarasvati                     https://t.co/yU2UNpVQjX?amp=1   \n",
       "\n",
       "                                                        description  \n",
       "@raisa6690        I'm a singer, in love forever with it. In it f...  \n",
       "@isyanasarasvati  Musician | \\n@redrose_records\\n | CP : +628131...  "
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "users_df = pd.DataFrame(users_info, index = [\"nb of following\",\n",
    "                                             \"nb of followers\",\n",
    "                                             \"join date\", \n",
    "                                             \"birthdate\",\n",
    "                                             \"location\",\n",
    "                                             \"website\",\n",
    "                                             \"description\"]).T\n",
    "users_df"
   ]
  }
 ],
 "metadata": {
  "colab": {
   "name": "Scraping with Python Library.ipynb",
   "provenance": [],
   "toc_visible": true
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
